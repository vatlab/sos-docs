{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# The `task` statement and option `-q`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "* **Difficulty level**: intermediate\n",
    "* **Time need to lean**: 30 minutes or less\n",
    "* **Key points**:\n",
    "   * Tasks are defined by `task` statement as part of substeps\n",
    "   * Tasks are executed independently of SoS process and can be executed on remote hosts, even if the host does not share file systems with local host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]",
    "tags": []
   },
   "source": [
    "## The concept of task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "<div class=\"bs-callout bs-callout-warning\" role=\"alert\">\n",
    "    <p><b>Tasks</b> are part of SoS substeps that are encapsulated and executed independently of the main workflow, possibly on remote hosts and cluster systems.</p>  \n",
    "</div>\n",
    "\n",
    "The idea behind tasks is that a workflow can contain a variety of substeps (scripts etc). Some of them are light weight and can be executed together with the workflow (on a local laptop or desktop), and some can be computational or resource intensive and have to be executed on the cluster, or have to be executed on specific remote hosts due to unavailablity of software or data.\n",
    "\n",
    "Whereas traditional workflow systems require all pieces of workflows to be executed on the same host, SoS allows you to send pieces of workflow to remote hosts, collect their results, and continue. This is achieved through a task mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## The `task` statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Technically speaking, a **substep** consists of everything after the `input` statement. It can be repeated with subsets of input files or parameters defined by input options `group_by` or `for_each`. For example, if `bam_files` is a list of bam files,\n",
    "\n",
    "```sos\n",
    "[10]\n",
    "input: bam_files, group_by=1\n",
    "output: f\"{_input}.bai\"\n",
    "\n",
    "print(f'Indexing {_input}')\n",
    "run: expand=True\n",
    "    samtools index {_input}\n",
    "```\n",
    "\n",
    "execute a shell script to process each bam file. This is done sequentially for each input file, and is performed by SoS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "You can easily specify part or all of a step process as **tasks**, by prepending the statements with a `task` keyword:\n",
    "\n",
    "\n",
    "```sos\n",
    "[10]\n",
    "input: bam_files, group_by=1\n",
    "output: f\"{_input}.bai\"\n",
    "\n",
    "print(f'Indexing {_input}')\n",
    "\n",
    "task:\n",
    "run: expand=True\n",
    "    samtools index {_input}\n",
    "```\n",
    "\n",
    "This statement declares the rest of the step process as a `task`. For each input file, a task will be created with an ID determined from task content and context (input and output files, variables etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": [],
    "toc-hr-collapsed": false
   },
   "source": [
    "## Specification of task queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "<div class=\"bs-callout bs-callout-hint\" role=\"alert\">\n",
    "    <h4>A <b>queue</b> is needed to execute a task</h4>\n",
    "    <p>The <code>task</code> statement will be ignored if no task queue is specified, either from command line with option <code>-q</code> or option <code>queue</code> of the <code>task</code> statement.</p>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### `task` statement is ignored by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Tasks need to be submitted to a **task queue** to be executed. If you do not specify queue, the task statement will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am task 0\n",
      "I am task 1\n"
     ]
    }
   ],
   "source": [
    "%run -v1\n",
    "\n",
    "input: for_each=dict(i=range(2))\n",
    "task:\n",
    "sh: expand=True\n",
    "  echo \"I am task {i}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Executing tasks in a `localhost` queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "If you do not have anything defined in `~/.sos/hosts.yml` (see [host configuration](host_setup.html) for details), a `localhost` task queue will be available to you. Technically speaking this is a `process` queue with a maximum of 10 concurrent jobs. To submit the task to this queue, you can specify it as the `queue` option of `task` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -v1\n",
    "\n",
    "input: for_each=dict(i=range(2))\n",
    "task: queue='localhost'\n",
    "sh: expand=True\n",
    "echo \"I am task {i}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "As you can see, two tasks are generated from two substeps. The tasks have different IDs (because they have different value for variable `i`) and are executed successfully on `localhost`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "A more convenient way to specify task queue is to use the `-q` option of command `sos run` (or magic `%run`,  `%sosrun`, or `%runfile`) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -q localhost -v1\n",
    "\n",
    "input: for_each=dict(i=range(2))\n",
    "task:\n",
    "sh: expand=True\n",
    "echo \"I am task {i}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "The differences between these two methods are that\n",
    "\n",
    "1. Task queue specified by option `-q` is applied to all tasks defined in the workflow\n",
    "2. If both `-q` and option `queue` are specified, task queue specified by option `quque` will be used for specific tasks.\n",
    "\n",
    "That is to say, you should generally use `-q` to send tasks to different task queue, and use `queue` for tasks that are designed for specified queues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Under the hood, two task files are created under `~/.sos/tasks` (e.g. `4fe780b5245b9e7b.task`) and SoS executes commands such as `sos execute 4fe780b5245b9e7b` to execute them, and collect result from the tasks. This is why you cannot see the output from the `echo \"I am task {i}\"` command executed by the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Executing tasks on remote servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "<p align=\"center\" height=\"500\">\n",
    "  <img src=\"https://vatlab.github.io/sos-docs/doc/media/remote_2_task.jpeg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "A `process` queue, like a localhost, execute the task directly, subject to the number of concurrent tasks. If you have a properly configured remote host (namely, have public-key authentication, have SoS installed, specified its `address`, `paths` etc in `hosts` configuration), you can send tasks to the remote host for execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "More specifically, with the following example, SoS\n",
    "\n",
    "1. Creates a task with an unique ID (`c600532cd99c02c2`) determined by the content of the task.\n",
    "2. Copy the task file to remote host, translating `input` and `output` paths if two systems have different file systems.\n",
    "3. Copy input files to remote host if needed.\n",
    "4. Execute the task by executing something like\n",
    "  ```\n",
    "  ssh host \"bash --login -c sos execute c600532cd99c02c2\"\n",
    "  ```\n",
    "5. Monitor the status of the task and update the status in the notebook.\n",
    "6. Copy the output file to local host if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "So with a host definition similar to the following\n",
    "\n",
    "```yaml\n",
    "hosts:\n",
    "  bcb:\n",
    "    address: bcbdesktop.mdanderson.edu\n",
    "    max_running_jobs: 100\n",
    "    paths:\n",
    "        home: /Users/{user_name}/scratch\n",
    "```\n",
    "\n",
    "I can submit a task with a `R` script to be executed on `bcb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: No matching tasks are identified. Use option -a to check all tasks.\n",
      "INFO: c600532cd99c02c2 \u001b[32mstarted\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -q bcb\n",
    "\n",
    "output: 'test1.png'\n",
    "task:\n",
    "R:\n",
    "  set.seed(1)\n",
    "  x <- 1:100\n",
    "  y <- -0.05*x + rnorm(100)\n",
    "  png(\"test1.png\", height=400, width=600)\n",
    "  plot(x, y, pch=19, col=rgb(0.5, 0.5, 0.5, 0.5), cex=1.5)\n",
    "  abline(lm(y ~ x))\n",
    "  dev.off()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "The output file is available locally after the completion of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview test1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "<div class=\"bs-callout bs-callout-hint\" role=\"alert\">\n",
    "    <h4>Difference between options <code>-q</code> and <code>-r</code></h4>\n",
    "    <p>If you have seen a similar example in <a href=\"remote_execution.html\">remote execution of workflows</a>, you will find that option <code>-r</code> and <code>-q</code> are similar in that they send the R script to remote host for execution. There are however a few key differences:\n",
    "<ul>\n",
    "  <li>Option <code>-r</code> execute the entire workflows on remote host while option <code>-q</code> only part of substeps. In particular, option <code>-r</code> starts one `sos run` process on remote host and option <code>-q</code> starts two <code>sos execute</code> processes on the remote host.</li>\n",
    "<li> Option <code>-r</code> uses input files on remote host and leaves output files on remote host. Option <code>-q</code> copies input files from local to remote host, and copies output files from remote to local host after the tasks are completed.</li>\n",
    "    </ul>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Executing tasks on a cluster system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "<p align=\"center\" height=\"500\">\n",
    "  <img src=\"https://vatlab.github.io/sos-docs/doc/media/remote_3_tasks.jpeg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "A server can also be a `pbs` queue, which represent a batch job management system such as Slurm, IBM LSF, or Torque. With proper configuration (again, see [host configuration](host_setup.html) for details), you will be able to submit your tasks to a cluster system as cluster jobs. The cluster system can be a localhost if you are submitting tasks on the headnode of a cluster system or a remote host (if you are submitting tasks remotely.\n",
    "\n",
    "For example, with a host configuration similar to\n",
    "\n",
    "\n",
    "```yaml\n",
    "hosts:\n",
    "     htc:\n",
    "        address: htc_cluster.mdanderson.edu\n",
    "        description: HTC cluster (PBS)\n",
    "        queue_type: pbs\n",
    "        status_check_interval: 60\n",
    "        submit_cmd: qsub {job_file}\n",
    "        status_cmd: qstat {job_id}\n",
    "        kill_cmd: qdel {job_id}        \n",
    "        nodes: 1\n",
    "        cores: 4\n",
    "        walltime: 01:00:00\n",
    "        mem: 4G\n",
    "        task_template: |\n",
    "            #!/bin/bash\n",
    "            #PBS -N {job_name}\n",
    "            #PBS -l nodes={nodes}:ppn={cores}\n",
    "            #PBS -l walltime={walltime}\n",
    "            #PBS -l mem={mem//10**9}GB\n",
    "            #PBS -o ~/.sos/tasks/{task}.out\n",
    "            #PBS -e ~/.sos/tasks/{task}.err\n",
    "            #PBS -m n\n",
    "            module load R\n",
    "            {command}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "You can submit your task to the cluster system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: No matching tasks are identified. Use option -a to check all tasks.\n"
     ]
    }
   ],
   "source": [
    "%run -q htc -s force\n",
    "\n",
    "output: 'test.png'\n",
    "task: walltime='1h', mem='2G', nodes=1, cores=1\n",
    "\n",
    "R:\n",
    "  set.seed(1)\n",
    "  x <- 1:100\n",
    "  y <- -0.03*x + rnorm(50)\n",
    "  png(\"test.png\", height=400, width=600)\n",
    "  plot(x, y, pch=19, col=rgb(0.5, 0.5, 0.5, 0.5), cex=1.5)\n",
    "  abline(lm(y ~ x))\n",
    "  dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Again, the output of the task will be synchronized to local host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview test.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Although the usage of the workflow is largely the same as the previous example, the `task` statement has a few options to specify the resources used by the task, as required by the cluster system. The value of these options will be used to expand a template specified in the host specification file to generate a shell script that will be created and copied to remote host. The generated shell script could be found in the `-v4` output of the `sos status` or magic `%task status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%task status 1fafb4489a7b4b47 -q htc -v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Then, instead of command\n",
    "```\n",
    "ssh host \"bash --login -c sos execute c600532cd99c02c2\"\n",
    "```\n",
    "as in the last example, a command like\n",
    "```\n",
    "ssh host \"bash --login -c qsub ~/.sos/tasks/1fafb4489a7b4b47.sh\"\n",
    "```\n",
    "was used to submit the job to the cluster system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "The entire workflow for executing tasks on a remote cluster system contains five steps and can be depicted as follows. The process would be a lot simpler if you are allowed to execute workflows and submit tasks on the headnode of a cluster system since no file synchronization would be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://vatlab.github.io/sos-docs/doc/media/task_overview.png\" width=\"80%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Task Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "The `task` statement accepts the following options\n",
    "\n",
    "| Option | Usage | reference | \n",
    "| -- | -- | --  | \n",
    "| `shared` | Return variable to the substep | this tutorial |\n",
    "| `env` | Customized environment | this tutorial |\n",
    "| `prepend_path` | Customized `$PATH` | this tutorial |\n",
    "| `walltime` | Total `walltime` of task | [task template](task_template.html) |\n",
    "| `mem` | Memory required for task | [task template](task_template.html)  |\n",
    "| `nodes` | Number of computing nodes | [task template](task_template.html)  |\n",
    "| `cores` | Number of cores per node | [task template](task_template.html)  |\n",
    "| `workdir` |  | [path translation and file synchronization ](task_files.html) |\n",
    "| `to_host` | | [path translation and file synchronization ](task_files.html) |\n",
    "| `from_host` | | [path translation and file synchronization ](task_files.html) |\n",
    "| `map_vars` | | [path translation and file synchronization ](task_files.html) |\n",
    "| ANY | Any template variable | [task template](task_template.html)  |\n",
    "\n",
    "We will discuss some options in this tutorial, and leave the rest to specific tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Option `shared`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "SoS tasks are executed externally and by default does not return any value. Similar to the `shared` step option (that passes step variables to the workflow), you can use `shared` option to pass task variables to the step in which the task is defined.\n",
    "\n",
    "For example, the following script perform some simulations in 10 tasks and return the result by variable `rng`, which is then shared to the workflow by step option `shared` so that it can be available to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 62f388838fadbc2f \u001b[32mstarted\u001b[0m\n",
      "898\n"
     ]
    }
   ],
   "source": [
    "%run -q localhost\n",
    "[10 (simulate): shared='rng']\n",
    "task: shared='rng'\n",
    "import random\n",
    "rng = random.randint(1, 1000)\n",
    "\n",
    "[20]\n",
    "print(rng)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos",
    "tags": []
   },
   "source": [
    "Also similar to step option `shared`, task option `shared` accepts a single variable (e.g. `rng`), a sequence of variables  (e.g. `('rng', 'sum')`), a dictionary of variable derived from an expression (e.g. `{'result': 'float(open(output).read())'}`, or sequences of names and variables. In the dictionary case, the values of the dictionary should be an expression (string), that will be evaluated upon the completion of the task, and assign to the specified variable.\n",
    "\n",
    "Please refer to [sharing variables across steps (step and task option `shared` and target `sos_variable`)](doc/user_guide/shared_variables.html) for more details on variable sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos",
    "tags": []
   },
   "source": [
    "### Option `env`\n",
    "\n",
    "The `env` option allow you to modify runtime environment, similar to the `env` parameter of the `subprocess.Popen` function. For example, you can set an environment variable `DEBUG` for the task as follows:\n",
    "\n",
    "```sos\n",
    "task:  env={'DEBUG': '1'}\n",
    "run:\n",
    "   mycommand \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos",
    "tags": []
   },
   "source": [
    "### Option `prepend_path`\n",
    "\n",
    "Option `prepend_path` prepend specified `paths` before `$PATH` before the task is executed. It provides a quick method to fix `$PATH` on a specific remote host.\n",
    "\n",
    "```sos\n",
    "task:  prepend_path='/path/to/mycommand'\n",
    "run:\n",
    "   mycommand \n",
    "```\n",
    "\n",
    "If you have found yourself using this option a lot for a remote host, consider adding the paths to the `task_template` with commands such as\n",
    "\n",
    "```sh\n",
    "export PATH=/path/to/mycommand:$PATH\n",
    "```\n",
    "or using host-specific methods to set up environment properly, e.g.\n",
    "```sh\n",
    "module load R/3.4.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Further reading\n",
    "\n",
    "* [Remote execution of workflow](remote_execution.html)\n",
    "* [Sharing variables across steps (step and task option `shared` and target `sos_variable`)](doc/user_guide/shared_variables.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.21.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
