{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# WGS Mapping to Variant Calls - Version 1.0\n",
    "\n",
    "Implementing one of the [`samtools` Workflows](http://www.htslib.org/workflow/#mapping_to_variant) in [SoS](https://github.com/vatlab/SOS). Some steps were re-implemented using `GATK4` instead of `GATK3` / `Pichard` or `samtools`, for better performance.\n",
    "\n",
    "**Multithreading: since GATK4 the multi-thread option `-nct` is not available. One has to use Spark version to achieve it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table class=\"revision_table\">\n",
       "        <tr>\n",
       "        <th>Revision</th>\n",
       "        <th>Author</th>\n",
       "        <th>Date</th>\n",
       "        <th>Message</th>\n",
       "        <tr>\n",
       "        <tr><td><a target=\"_blank\" href=\"git@github.com:vatlab/sos-docs/blob/b98d99ebb16666979b617db95dcd243903711309/WGS_Call.ipynb\"><span class=\"revision_id\">b98d99e<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-09-03</td>\n",
       "<td>Update docker option</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:vatlab/sos-docs/blob/3bf8f4dd4a6a3a8cbd9cfd5019ac39fb8d243f1a/WGS_Call.ipynb\"><span class=\"revision_id\">3bf8f4d<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-09-03</td>\n",
       "<td>Add a step to select given list of variants</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:vatlab/sos-docs/blob/33fd12cb7d223ae379484d38472f2438437139bf/WGS_Call.ipynb\"><span class=\"revision_id\">33fd12c<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-09-03</td>\n",
       "<td>Get toy example to work</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:vatlab/sos-docs/blob/8f3b701b2e3bcd99b30714b9b15e5dd16210343f/WGS_Call.ipynb\"><span class=\"revision_id\">8f3b701<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-09-03</td>\n",
       "<td>Add links to toy reference data</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%revisions -s -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This SoS workflow notebook contains three workflows:\n",
    "\n",
    "- `get_ref_genome` which downloads reference genome data, in preparation for genotype calling\n",
    "- `get_known_variants` which downloads known variants data, in preparation of genotype calling\n",
    "- `default`, a sequence of commands to perform multi-sample genotype calling for given list of samples\n",
    "\n",
    "All workflow steps are numerically ordered to reflect the execution logic. This is the most straightforward SoS workflow style, the \"process-oriented\" style. \n",
    "\n",
    "To view available workflows and options,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run WGS_Call.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  get_ref_genome\n",
      "  get_known_variants\n",
      "  default\n",
      "\n",
      "Global Workflow Options:\n",
      "  --samples . (as path)\n",
      "                        a file containing sample names\n",
      "  --wd WGS_Call_SoS (as path)\n",
      "                        work directory\n",
      "  --ref-genome  path(f'{wd:a}/ref/reference.fa')\n",
      "\n",
      "                        name of reference genome file\n",
      "  --ref-variants  path(f'{wd:a}/ref/known_variants.vcf.gz')\n",
      "\n",
      "                        name of known variant sites file\n",
      "  --ref-indel  path(f'{wd:a}/ref/known_variants.vcf.gz')\n",
      "\n",
      "                        name of known indel file\n",
      "  --genome-url 'https://github.com/vatlab/sos-docs/raw/master/src/examples/k9-test/reference.fa.gz'\n",
      "                        download link for reference fasta file, in gz format\n",
      "  --variants-url 'https://github.com/vatlab/sos-docs/raw/master/src/examples/k9-test/known.vcf.gz'\n",
      "                        download link for known variants vcf file, in gz format\n",
      "  --[no-]zap (default to False)\n",
      "                        whether or not to remove files from intermediate steps\n",
      "  --bcftools-filter '%QUAL>10'\n",
      "                        bcftools default quality filter\n",
      "  --ncpu 3 (as int)\n",
      "                        number of CPU threads to use per process\n",
      "  --chr-prefix chr\n",
      "                        can be empty, or chr, or Chr depending on input data-\n",
      "                        set.\n",
      "  --n-chrom 38 (as int)\n",
      "                        Human is 23, Bovine is 29, Canine is 38; we focus on\n",
      "                        autosome and X.\n",
      "  --[no-]variants-only (default to False)\n",
      "                        Set to True to only call variant sites not \"wildtype\"\n",
      "  --keep-coord . (as path)\n",
      "                        Keep a list of specified variants only\n",
      "\n",
      "Sections\n",
      "  get_ref_genome_1:     Download reference genome\n",
      "  get_ref_genome_2:     Index reference genome\n",
      "  get_known_variants_1: Download known variants\n",
      "  get_known_variants_2: Index known variants\n",
      "  default_0:            Export workflow to HTML file\n",
      "  default_1:            BWA mapping & samtools postprocessing\n",
      "  default_2:            Sort BAM files\n",
      "  default_3:            Extract relevant chromosomes for analysis\n",
      "  default_4:            Re-order bam files\n",
      "  default_5:            Indel re-alignment\n",
      "  default_6:            Base recalibration\n",
      "  default_7:            Mark duplicates\n",
      "  default_8:            Multi-sample variant calling -- pileup\n",
      "  default_9:            Multi-sample variant calling -- call\n",
      "  default_10:           Quality summary plots for VCF file\n",
      "  default_11:           Quality filtering\n",
      "  default_12:           Only extract regions we are interested in\n"
     ]
    }
   ],
   "source": [
    "!sos run WGS_Call.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input data\n",
    "\n",
    "Input in `fastq` format, paired-ended:\n",
    "\n",
    "```\n",
    "Sample_75641_2.fq.gz Sample_75641_2.fq.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Reference data preparation\n",
    "\n",
    "To prepare reference genome data, run:\n",
    "\n",
    "```\n",
    "sos run WGS_Call.ipynb get_ref_genome\n",
    "```\n",
    "\n",
    "To prepare reference known variants data, run:\n",
    "\n",
    "```\n",
    "sos run WGS_Call.ipynb get_known_variants\n",
    "```\n",
    "\n",
    "These commands will download reference data to `./WGS_Call_SoS/ref` \n",
    "(work directory, can be configured via `--wd` option as shown in the workflow help message above). \n",
    "\n",
    "If you already have reference genome data bundle and known variants data you can use `--ref-genome`, \n",
    "`--ref-variants` and `--ref-indel` to specify them. Otherwise you should edit `get_ref_genome` and `get_known_variants`\n",
    "steps below to download them. The default is pointed to a toy example data-set for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Run the workflow\n",
    "\n",
    "The workflow has been tested on Linux and Mac. \n",
    "In brief, after installing [SoS](https://github.com/vatlab/SOS) (see \"Software Configuration\" below), \n",
    "you provide a text file of sample list named eg `k9-test/test_samples.manifest`, with contents:\n",
    "\n",
    "```\n",
    "Sample_79162\n",
    "Sample_75641\n",
    "```\n",
    "\n",
    "Under the same folder as this list file, you keep all the listed sample `fastq` files. Then you run\n",
    "\n",
    "```\n",
    "sos run WGS_Call.ipynb --samples k9-test/test_samples.manifest -j2\n",
    "```\n",
    "\n",
    "to perform variant calling. `-j2` option means to run 2 processes in parallel. \n",
    "After it completes you'll find under folder `./WGS_Call_SoS` (can be configured):\n",
    "\n",
    "1. `WGS_Call.html` of this document\n",
    "2. `bam` folder of intermediate and processed BAM files. Only BAM files from the last preprocessing step is kept by default, unless option `--no-zap` (which changes `parameter: zap = ...` in the workflow) is appended to the command above.\n",
    "3. `vcf` folder of genotype call. The final output is `vcf/test_samples.filtered.vcf.gz` -- the file name is derived after your input sample list `/path/to/this/test_samples.manifest`\n",
    "\n",
    "\n",
    "You can also \"dryrun\" the workflow to see what is actually going on:\n",
    "\n",
    "```\n",
    "sos dryrun WGS_Call.ipynb --samples k9-test/test_samples.manifest\n",
    "```\n",
    "\n",
    "Or, run / dryrun a few steps, eg, the first 5 steps.\n",
    "\n",
    "```\n",
    "sos dryrun WGS_Call.ipynb default:1-5 --samples k9-test/test_samples.manifest\n",
    "```\n",
    "\n",
    "`dryrun` will print out all commands which you can collect to a file and run them separately (for debugging, for example).\n",
    "\n",
    "### Do we keep all loci even if they are not variants?\n",
    "\n",
    "Yes we do (for obvious reasons)! This is why `--variants_only` is `False` by default. However it is a huge file to work on. We include an option `--keep_coord` that provides a list of genomic coordinates like this:\n",
    "\n",
    "```\n",
    "1\t2815013\n",
    "1\t7421527\n",
    "1\t11653215\n",
    "1\t12326997\n",
    "1\t14892273\n",
    "1\t16663755\n",
    "```\n",
    "\n",
    "This case, only selected loci (variants of interest) are kept for further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Software configuration\n",
    "\n",
    "To install SoS, make sure you have Python 3.6, then:\n",
    "\n",
    "```\n",
    "pip install -U sos sos-notebook sos-pbs\n",
    "python -m sos_notebook.install\n",
    "```\n",
    "\n",
    "To open the notebook:\n",
    "\n",
    "```\n",
    "jupyter notebook WGS_Call.ipynb &> /dev/null &\n",
    "```\n",
    "\n",
    "If you do not already have `sos_notebook` on your computer, you will need to close this notebook after installation and open it again to see the `sos_notebook` kernel take effect in your Juptyer.\n",
    "\n",
    "To better display notebook edits from `git`:\n",
    "\n",
    "```\n",
    "pip install nbdime\n",
    "nbdime config-git --enable --global\n",
    "```\n",
    "\n",
    "Finally you need to install and configure `docker`:\n",
    "\n",
    "1. Run commands below:\n",
    "```\n",
    "curl -fsSL get.docker.com -o get-docker.sh\n",
    "sudo sh get-docker.sh\n",
    "sudo usermod -aG docker $USER\n",
    "```\n",
    "2. Log out and log back in (no need to reboot computer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# a file containing sample names\n",
    "parameter: samples = path() \n",
    "# work directory\n",
    "parameter: wd = path('./WGS_Call_SoS')\n",
    "# name of reference genome file\n",
    "parameter: ref_genome = path(f'{wd:a}/ref/reference.fa')\n",
    "# name of known variant sites file\n",
    "parameter: ref_variants = path(f'{wd:a}/ref/known_variants.vcf.gz')\n",
    "# name of known indel file\n",
    "parameter: ref_indel = path(f'{wd:a}/ref/known_variants.vcf.gz')\n",
    "# download link for reference fasta file, in gz format\n",
    "parameter: genome_url = \"https://github.com/vatlab/sos-docs/raw/master/src/examples/k9-test/reference.fa.gz\"\n",
    "# download link for known variants vcf file, in gz format\n",
    "parameter: variants_url = \"https://github.com/vatlab/sos-docs/raw/master/src/examples/k9-test/known.vcf.gz\"\n",
    "# whether or not to remove files from intermediate steps\n",
    "parameter: zap = True\n",
    "# bcftools default quality filter\n",
    "parameter: bcftools_filter = '%QUAL>10'\n",
    "# number of CPU threads to use per process\n",
    "parameter: ncpu = 3\n",
    "# can be empty, or chr, or Chr depending on input data-set.\n",
    "parameter: chr_prefix = 'chr'\n",
    "# Human is 23, Bovine is 29, Canine is 38; \n",
    "# we focus on autosome and X.\n",
    "parameter: n_chrom = 38\n",
    "chroms = ' '.join([f'{chr_prefix}{x+1}' for x in range(n_chrom)] + [f'{chr_prefix}X'])\n",
    "# Set to True to only call variant sites not \"wildtype\"\n",
    "parameter: variants_only = False\n",
    "# Keep a list of specified variants only\n",
    "parameter: keep_coord = path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Reference preparation\n",
    " \n",
    "### Reference genome\n",
    "\n",
    "Use primary assembly sequence. See [this post](https://bioinformatics.stackexchange.com/questions/540/what-ensembl-genome-version-should-i-use-for-alignments-e-g-toplevel-fa-vs-p?rq=1) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Download reference genome\n",
    "[get_ref_genome_1]\n",
    "output: ref_genome\n",
    "download: dest_file = f'{_output}.gz', expand = True\n",
    "    {genome_url}\n",
    "bash: expand = True\n",
    "    zcat {ref_genome}.gz > {ref_genome}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "create reference index and dict files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Index reference genome\n",
    "[get_ref_genome_2]\n",
    "output: f'{ref_genome:n}.dict'\n",
    "run: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    samtools faidx {_input} && \\\n",
    "    bwa index {_input} && \\\n",
    "    gatk CreateSequenceDictionary -R {_input} -O {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Known sites\n",
    "\n",
    "[NCBI dbSNP](ftp://ftp.ncbi.nih.gov/snp/organisms/archive) has reference SNP files for various species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Download known variants\n",
    "[get_known_variants_1]\n",
    "output: f'{ref_variants:nn}.unsorted.vcf.gz'\n",
    "download: dest_file = f'{_output}', expand = True\n",
    "    {variants_url}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Sort and index VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Index known variants\n",
    "[get_known_variants_2]\n",
    "output: ref_variants\n",
    "bash: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    gatk SortVcf -I {_input} -O {_output} \\\n",
    "        --SEQUENCE_DICTIONARY {ref_genome:n}.dict \\\n",
    "        --COMPRESSION_LEVEL 9 && \\\n",
    "    gatk IndexFeatureFile -F {_output}\n",
    "if zap:\n",
    "    _input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The standard workflow for working with DNA sequence data consists of three major steps:\n",
    "\n",
    "- Mapping\n",
    "- Improvement\n",
    "- Variant Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Export workflow to HTML file\n",
    "[0]\n",
    "input: [item for item in sys.argv if item.endswith('.ipynb')], group_by = 1, pattern = '{fn}.ipynb'\n",
    "output: expand_pattern(f'{wd:a}/{path(_fn[0]):b}.html')\n",
    "bash: expand=True, stderr=False\n",
    "  sos convert {_input} {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "We skip the `bwa` steps because our data has already been mapped. \n",
    "\n",
    "Because BWA can sometimes leave unusual FLAG information on SAM records, it is helpful when working with many tools to first clean up read pairing information and flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# BWA mapping & samtools postprocessing\n",
    "[1]\n",
    "fail_if(not samples.is_file(), msg = 'Need sample name list file!')\n",
    "sample_files = list(set(get_output(f\"awk '{{print $1}}' {samples:e}\").strip().split('\\n')))\n",
    "fail_if(len(sample_files) == 0, msg = 'Need input sample files!')\n",
    "input: [(f'{samples:d}/{x}_1.fq.gz', f'{samples:d}/{x}_2.fq.gz') for x in sample_files], group_by = 2, concurrent = True\n",
    "output: f'{wd:a}/{samples:bn}_bam/{_input[0]:bnn}.fixmate.bam'\n",
    "run: container='gaow/debian-ngs', volumes=[f'{samples:da}:{samples:da}', f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    bwa mem -t {ncpu} -M -R \"@RG\\\\tID:{os.path.basename(sample_files[_index].replace('-', '_'))}\\\\tSM:{os.path.basename(sample_files[_index].replace('-', '_'))}\\\\tLB:library1\\\\tPL:ILLUMINA\\\\tPU:{os.path.basename(sample_files[_index].replace('-', '_'))}.library1\" {ref_genome} {_input[0]} {_input[1]} | samtools sort -n - | samtools fixmate -O bam - {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To sort them from name order into coordinate order,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Sort BAM files\n",
    "[2]\n",
    "# sort via GATK4 is way faster\n",
    "# https://software.broadinstitute.org/gatk/blog?id=9644\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.sorted.bam'\n",
    "run: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    gatk SortSam -I {_input} -O {_output} -SO coordinate\n",
    "if zap:\n",
    "    _input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "We extract relevant chromosomes and re-order to match ordering in reference,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Extract relevant chromosomes for analysis\n",
    "[3]\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.cleaned.bam'\n",
    "run: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    samtools index {_input}\n",
    "    samtools view -@ {ncpu} -b {_input} {chroms} > {_output}\n",
    "if zap:\n",
    "    _input.zap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Re-order bam files\n",
    "[4]\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.reordered.bam'\n",
    "run: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    gatk ReorderSam -I {_input} -O {_output} -R {ref_genome} \\\n",
    "        --CREATE_INDEX TRUE \\\n",
    "        --ALLOW_INCOMPLETE_DICT_CONCORDANCE TRUE\n",
    "if zap:\n",
    "    _input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Improvement\n",
    "\n",
    "In order to reduce the number of miscalls of INDELs in your data it is helpful to realign your raw gapped alignment with the Broad’s GATK3 Realigner. This is necessary only when used with other genotype callers. In GATK4 best practice pipeline this step can be skipped if HaplotypeCaller is used.\n",
    "\n",
    "Note: option `-nct` does not apply to `RealignerTargetCreator` and `IndelRealigner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Indel re-alignment\n",
    "[5]\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.realigned.bam'\n",
    "run: container='gaow/gatk3', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    java -jar /opt/GenomeAnalysisTK.jar -T RealignerTargetCreator \\\n",
    "        -R {ref_genome} \\\n",
    "        -I {_input} \\\n",
    "        -o {_input:n}.intervals \\\n",
    "        --known {ref_indel} && \\\n",
    "    java -jar /opt/GenomeAnalysisTK.jar -T IndelRealigner \\\n",
    "        -R {ref_genome} \\\n",
    "        -I {_input} \\\n",
    "        -targetIntervals {_input:n}.intervals \\\n",
    "        -known {ref_indel} \\\n",
    "        -o {_output}\n",
    "if zap:\n",
    "    _input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "BQSR from the Broad’s GATK allows you to reduce the effects of analysis artefacts produced by your sequencing machines. It does this in two steps, the first analyses your data to detect covariates and the second compensates for those covariates by adjusting quality scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Base recalibration\n",
    "[6]\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.recal.bam'\n",
    "run: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output}.err', stdout=f'{_output}.out'\n",
    "    gatk BaseRecalibrator \\\n",
    "        -R {ref_genome} \\\n",
    "        --known-sites {ref_variants} \\\n",
    "        -I {_input} -O {_input:n}.table && \\\n",
    "    gatk ApplyBQSR -I {_input} -bqsr {_input:n}.table -O {_output} # --create-output-bam-index TRUE\n",
    "if zap:\n",
    "    _input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "It is helpful at this point to compile all of the reads from each library together into one BAM, which can be done at the same time as marking PCR and optical duplicates. To identify duplicates we currently recommend the use of either the Picard or biobambam’s mark duplicates tool.\n",
    "\n",
    "*The following step only Marks duplicates instead of removing duplicates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Mark duplicates\n",
    "[7]\n",
    "input: group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.dedup.bam'\n",
    "run: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    gatk MarkDuplicates \\\n",
    "        --VALIDATION_STRINGENCY LENIENT \\\n",
    "        --INPUT {_input} --OUTPUT {_output} \\\n",
    "        --METRICS_FILE {_output:n}.metrics_file \\\n",
    "        --CREATE_INDEX TRUE\n",
    "if zap:\n",
    "    _input.zap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Variant Calling\n",
    "To convert your BAM file into genomic positions we first use mpileup to produce a BCF file that contains all of the locations in the genome. We use this information to call genotypes and reduce our list of sites to those found to be variant by passing this file into bcftools call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Multi-sample variant calling -- pileup\n",
    "[8]\n",
    "# the 2nd line can have many samples separated by space\n",
    "output: f'{wd:a}/{samples:bn}_vcf/{samples:bn}.bcf'\n",
    "run: container='gaow/debian-ngs', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    bcftools mpileup -Ob -f {ref_genome} --threads {ncpu} -o {_output} {_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Multi-sample variant calling -- call\n",
    "[9]\n",
    "output: f'{_input:n}.vcf.gz'\n",
    "run: container='gaow/debian-ngs', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    bcftools call -{\"v\" if variants_only else \"\"}mO z --threads {ncpu} -o {_output} {_input} \\\n",
    "    && tabix -p vcf {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Additionally you may find it helpful to prepare graphs and statistics to assist you in filtering your variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Quality summary plots for VCF file\n",
    "[10]\n",
    "output: f'{_input:n}.stats'\n",
    "run: container='gaow/debian-ngs-gatk4', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    bcftools stats -F {ref_genome} -s - {_input} > {_output}\n",
    "    mkdir -p {_input:nn}_plots\n",
    "    plot-vcfstats -P -p {_input:nn}_plots {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Finally you will probably need to filter your data using commands such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Quality filtering\n",
    "[11]\n",
    "output: f'{_input:nn}.filtered.vcf.gz'\n",
    "run: container='gaow/debian-ngs', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    bcftools filter -O z -o {_output} \\\n",
    "        -s LOWQUAL -i'{bcftools_filter}' {_input:nn}.vcf.gz \\\n",
    "    && tabix -p vcf {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Variant filtration is a subject worthy of an article in itself and the exact filters you will need to use will depend on the purpose of your study and quality and depth of the data used to call the variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Only extract regions we are interested in\n",
    "[12]\n",
    "stop_if(not keep_coord.is_file(), msg = 'Skip extracting selected SNPs because no list (--keep_coord coord.list) was provided to extract from.')\n",
    "output: f'{_input:nn}.extracted.vcf.gz'\n",
    "run: container='gaow/debian-ngs', volumes=[f'{wd:a}:{wd:a}'], expand=True, stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    tabix -H {_input} > {_output:n}\n",
    "    tabix {_input} -R {keep_coord} >> {_output:n}\n",
    "    bgzip {_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## References\n",
    "- The 1000 Genomes Project Consortium - An Integrated map of genetic variation from 1092 human genomes Nature 491, 56–65 (01 November 2012) doi:10.1038/nature11632\n",
    "- [GATK Best Practices](http://www.broadinstitute.org/gatk/guide/best-practices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.16.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
