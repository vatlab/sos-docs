{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution of tasks on remote hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "SoS allows you to execute tasks on remote hosts or task queues with or without their own file systems. For example, you can execute a complex workflow mostly locally, but execute a few tasks on a remote host if it provides more computing power, or if it has some software that cannot be installed locally. The remote host could have its own file system (separate systems), share its file system with the local machine (e.g. nodes on the cluster), or share some storage with the local machine (e.g. have the same shared storage), so file synchronization will be needed in some cases.\n",
    "\n",
    "With help from a few runtime options (options to `task`), SoS can\n",
    "\n",
    "* Copy specified local files to the remote host, possibly to different directories\n",
    "* Start a SoS task on the remote machine or submit the tak to a task queue (e.g. PBS or Celery) and wait for the completion of the task\n",
    "* Copy results back from the remote host if the execution is successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## System setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Public-key access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Following any online tutorial, set up public-key access from your local machine to the remote host. If your public key does not work, check file permissions of `~/.ssh`, files under `.ssh`, and `$HOME` in some cases. After setting up the server, make sure you can login without password using command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "```bash\n",
    "% ssh remote-host\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Software installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "You will need to install the latest version of sos (preferrably identical version between local and remote hosts), and the software you will need to run. Test it by logging to the remote machine with commands\n",
    "\n",
    "```bash\n",
    "% sos -h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Check `$PATH`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Commands that are available in login shell are not necessarily available during remote execution. Basically, remote execution through `ssh` invokes a non-interactive and non-login shell with basic `$PATH`. SoS tries to address this problem by executing commands through a login shell\n",
    "\n",
    "```bash\n",
    "% ssh remote-host \"bash --login -c 'sos execute task_id'\"\n",
    "```\n",
    "\n",
    "However, default `.bashrc` on the remote server might contain a line like\n",
    "\n",
    "```bash\n",
    "[ -z \"$PS1\" ] && return\n",
    "```\n",
    "\n",
    "that makes it exit when `bash` is not running interactively. This line has to be removed in order to have complete `$PATH` during remote execution.\n",
    "\n",
    "Now, fire command\n",
    "\n",
    "```bash\n",
    "% ssh remote-host \"bash --login -c 'sos -h'\"\n",
    "```\n",
    "\n",
    "from your local machine and see if `sos` can be invoked. Similarly, verify if the command you would like to execute remotely can be executed in this manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Configure local and remote hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Now you need to configure your local and remote hosts so that SoS knows how to communicate between them. The hosts configurations should be defined in `~/.sos/hosts.yml`, and should look similar to\n",
    "\n",
    "```\n",
    "hosts:\n",
    "    desktop:\n",
    "        paths:\n",
    "            home: /Users/myuser\n",
    "    monster:\n",
    "        address: dcdr1ue8ee.yourdomain.com\n",
    "        paths:\n",
    "            home: /home/myuser\n",
    "```\n",
    "\n",
    "The format is easy enough to edit directly, but you can also use commands such as\n",
    "\n",
    "```\n",
    "% sos config --hosts --set hosts.monster.address dcdrlue8ee.yourdomain.com\n",
    "```\n",
    "\n",
    "to add or change key `hosts['monster']['address']` to `dcdrlue8ee.yourdomain.com`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Configure `address`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "You should specify in the `hosts` section the address of remote host, similar to\n",
    "\n",
    "```\n",
    "hosts:\n",
    "  monster:\n",
    "    address: dcdrlue8ee.yourdomain.com\n",
    "```\n",
    "\n",
    "If your account name differs between the local and remote servers, the complete address should be `username@address`. In this example `john@dcdrlue8ee.yourdomain.com` if the remote server account is `john`.\n",
    "\n",
    "You can also specify `address` for your localhost if you plan to remotely login to the localhost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Configure `paths`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "`paths` is a list of directories that will be translated between hosts. For example, if you work locally on a Mac machine with home directory `/Users/myuser`, and the remote server is a Linux machine with home directory `/home/myuser`, you should define a `paths` with definitions of `home` as follows:\n",
    "\n",
    "```\n",
    "hosts:\n",
    "    desktop:\n",
    "        paths:\n",
    "            home: /Users/myuser\n",
    "    monster:\n",
    "        address: dcdr1ue8ee.yourdomain.com\n",
    "        paths:\n",
    "            home: /home/myuser\n",
    "```\n",
    "\n",
    "In this way, if the local data is `/User/myuser/projects/input.fastq`, the path will be translated to `/home/myuser/projects/input.fastq` during remote execution.\n",
    "\n",
    "In more complicated cases where there are different directories, more than one `paths` can be specified. For example, if you have directories under different volumes, you can map them differently using\n",
    "\n",
    "```bash\n",
    "hosts:\n",
    "    desktop:\n",
    "        paths:\n",
    "            home: /Users/myuser\n",
    "            project: /Users/myuser/projects\n",
    "            resource: /Volumes/Resource\n",
    "    monster:\n",
    "        address: dcdr1ue8ee.yourdomain.com\n",
    "        paths:\n",
    "            home: /home/myuser\n",
    "            project: /home/myuser/scratch/projects\n",
    "            resource: /home/myuser/resource\n",
    "```\n",
    "\n",
    "Note that\n",
    "\n",
    "1. You can define multiple `paths` such as `home`, `scratch`, `working`, `resource`, but **paths should be defined for all hosts**.\n",
    "2. All `paths` should be absolute (starts with `/` for Linux-like systems).\n",
    "3. SoS expands local directories to absolute path before matching to a `paths`.\n",
    "4. If there are multiple matches, SoS choose the longest-matching path. For example, path `/Users/myuser/projects/input.txt` would be identified as `project` (not `home`) and be mapped to `/home/myuser/scratch/projects/input.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos",
    "output_cache": "[]"
   },
   "source": [
    "### Configure `shared`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Option `shared` tells SoS which file systems are shared between local and remote hosts so that it does not have to synchronize files under these directories between the hosts.\n",
    "\n",
    "* SoS assumes independent file systems so you do not have to specify option `shared` if the local and remote hosts does not share any file system.\n",
    " \n",
    "* If your local and remote host share all file systems, you should list `/` as shared.\n",
    "\n",
    "    ```\n",
    "    hosts:\n",
    "        desktop:\n",
    "            shared:\n",
    "                ALL: /\n",
    "        monster:\n",
    "            shared:\n",
    "                ALL: /\n",
    "    ```\n",
    "    The name `ALL` does not matter as long as they match between hosts.\n",
    "\n",
    "  \n",
    "* If your local and remote host share one or more shared volumes, you can specify them with\n",
    "\n",
    "    ```    \n",
    "    hosts:\n",
    "        desktop:\n",
    "            shared:\n",
    "                project: /project\n",
    "        monster:\n",
    "            shared:\n",
    "                project: /scratch/project\n",
    "    ```\n",
    "  \n",
    "  to indicate that local files under `/project` shared to `monster`.\n",
    "\n",
    "Items under `shared` are treated as special `paths`. Files under these directories are mapped, but not synchronized.\n",
    "\n",
    "Note that it is a bad idea to use dropbox or google drive as shared drives because files under these directories are not actually shared so a file created locally will not be available instantly on the remote host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Specify `localhost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "After you configure both local and remote host, you will need to tell sos what your `localhost` is in the `hosts` list using command\n",
    "\n",
    "```\n",
    "% sos config --global --set localhost desktop\n",
    "```\n",
    "\n",
    "which actually writes `localhost: desktop` in the system configuration file. \n",
    "\n",
    "If you have defined multiple hosts in the `hosts.yml` file, you should distribute this file to all hosts and set `localhost` accordingly, so that all machines know how to communicate with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Sample configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "The server settings are critically important for the successful execution of commands on remote servers. As an example, I am working on a Mac mini (with limited CPU/RAM) and have access to a Mac Pro workstation and a Linux server. The hosts configurations for these machines are\n",
    "\n",
    "```\n",
    "hosts:\n",
    "  mini:\n",
    "    paths:\n",
    "      home: /Users/bpeng1\n",
    "      resource: /Users/bpeng1/.sos/resource\n",
    "  macpro:\n",
    "    address: mp-bpeng.mdanderson.edu\n",
    "    paths:\n",
    "      home: /Users/bpeng1\n",
    "      resource: /Volumes/HOME/resource\n",
    "  linux:\n",
    "    address: dcdrlpmcfd.mdanderson.edu\n",
    "    paths:\n",
    "      home: /home/bpeng1\n",
    "      resource: /home/bpeng1/.sos/resource\n",
    "```\n",
    "\n",
    "I defined two `paths` named `home` and `resource` because although `resource` is at the same location `~/.sos/resource`, it is in a dedicated volume `/Volumes/HOME/` on the macpro.\n",
    "\n",
    "With this `hosts.yml` and proper definition of `localhost` on each machine, it is possible to submit jobs from `mini` to `macpro` and `linux`, from `macpro` to `linux` and from `linux` to `macpro`. It is not possible to submit jobs remotely to `mini` because no `address` is defined for this host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Running tasks remotely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `queue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "If you have set up a host in SoS configuration file propertly, you can use option `queue` to specify the host on which the task will be executed.\n",
    "\n",
    "```\n",
    "task:   queue='monster'\n",
    "```\n",
    "\n",
    "Here `monster` is the alias of the host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Command line option `-q`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Command line option `-q` specify a default task queue (or remote host) to which all tasks would be submitted. This option does not override `queue` options defined in the script so you can submit most jobs to a queue while submitting some jobs to particular servers (e.g. the one with specific software) using task options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Options `to_host` and `from_host`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your machine configured, you should try to copy some files and see if they work correctly. File copy is specified with options `to_host` and `from_host`, which accepts a single file or directory name (string) or list (or nested lists) of filenames relative to local file system. You can test these options using simple SoS steps such as (replace filenames with files you have, of course),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "```sos\n",
    "[1]\n",
    "task: \n",
    "    queue: 'monster',\n",
    "    to_host: ['~/projects/data/test1', '/Volumes/Resources/hg19.fasta'],\n",
    "    from_host: '~/projects/data/test1.res'\n",
    "run:\n",
    "    echo \"Hello, World\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "**Input, dependent, and output files are automatically transferred** so `to_host` and `from_host` are only needed to transfer files or directories in addition to step input and outputs. If there is any problem with file transfer, use option `-v3` to check if filenames are mapped correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each task has a **context dictionary** that contains variables that will be used to, for example, compose scripts to be executed. When the script is executed on the remote host, targets specified in variables `input` (`_input`), `output` (`_output`), `depends` (`_depends`) will be **translated synchronized from local to remote file system** (unless they are of type `remote`). The values of these variables will be translated on remote host.\n",
    "\n",
    "If there are additional files that you would like to synchronize, you should put them in `input:` or `depends:` statement. If for any reason you would like to translate a variable from local to remote host but do not want to synchronize the file, you can add it to option `map_vars`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Running task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "With all the pieces put together, you can now execute the task on the remote host using `task` options\n",
    "\n",
    "```sos\n",
    "depends:  hg19_fasta, hg19_genes_gtf\n",
    "output:   \"${hg19_star_index}/chrName.txt\"\n",
    "task:     queue='monster', from_host=hg19_star_index\n",
    "run:\n",
    "    STAR \\\n",
    "        --runThreadN 8 \\\n",
    "        --runMode genomeGenerate \\\n",
    "        --genomeDir ${hg19_star_index} \\\n",
    "        --genomeFastaFiles ${hg19_fasta} \\\n",
    "        --sjdbGTFfile ${hg19_genes_gtf} \\\n",
    "        --sjdbOverhang 100\n",
    "```\n",
    "\n",
    "For this example,\n",
    "\n",
    "1. SoS automatically transfers all input (None in this example) and dependent files (`hg19_fasta1 and `hg19_genes_gtf` in this example) so no `to_host` is needed.\n",
    "2. Option `from_host` is needed because we need to transfer not only the reprsenting output file (`hg19_star_index}/chrName.txt`), but also the whole directory containing the whole indexes (`hg19_star_index`).\n",
    "\n",
    "SoS tries its best to automate the process while allowing you to tweak the details with runtime options. Just to recap the use of these  options:\n",
    "\n",
    "* `to_host` is needed to transfer **additional input** files or directories to remote host.\n",
    "* `from_host` is needed to tranfer **additional output** files or directories from remote host.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Monitor the status of the remote task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Tasks executed on remote servers are external in the sense that they could be monitored and killed externally. When you submit the task, you will be given a task ID, using which you can query the status of the task or cancel the tak. For example,\n",
    "\n",
    "```\n",
    "sos status task_id -q shark\n",
    "```\n",
    "\n",
    "can be used to check the status of `task_id` on a remote server `shark`, and command\n",
    "\n",
    "```\n",
    "sos kill task_id -q shark\n",
    "``` \n",
    "can be used to kill a running task with ID `task_id`. You can also use command \n",
    "\n",
    "```\n",
    "sos status task_id -q shark -v 3\n",
    "```\n",
    "to display the details of task, including the SoS (Python) statements that will be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Submit tasks to a task queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Instead of executing the task directly on a remote server, you can submit the task to a task queue (e.g. PBS/Torch of a cluster sytem) where the task could be distributed to working nodes of a cluster system. A little more configuration would be needed, basically, you will need to configure\n",
    "\n",
    "* `queue_type`: type of the task queue\n",
    "\n",
    "and for `queue_type = pbs`, configurations such as\n",
    "\n",
    "* `job_template`: A template to generate jobs to be submitted,\n",
    "* `submit_cmd`: command to submit PBS jobs,\n",
    "* `status_cmd`: command to check status of jobs, and\n",
    "* `kill_cmd`: command to cancel/delete pending or running jobs.\n",
    "\n",
    "You will also need to specify the resources needed to execute your task, using task options such \n",
    "\n",
    "* `walltime`: estimated time\n",
    "* `mem`: estimated memory usage\n",
    "* `procs`: number of process needed for the task\n",
    "\n",
    "With these configurations and options properly set up, you will be able to execute the task using the same syntax, e.g.\n",
    "\n",
    "```\n",
    "sos run myscript -q pbs\n",
    "sos status -q pbs\n",
    "sos kill tasks -q pbs\n",
    "```\n",
    "\n",
    "where `pbs` is the alias of the cluster system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### An example using docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Here is real-world example of running a bioinformatics tool (`tophat2`) on a remote server using docker. The remote server is a Linux server with docker installed. The local machine has all the reference data and annotation files (`hg19_fasta`, `hg19_genes_gtf`), and the Bowtie2 index (`hg19_Bowtie2_index`) but do not have tophat installed (lacking a Python 2 environment).\n",
    "\n",
    "The following step runs tophat2 on the input fastq files using a remote host (with alias `linux`) and docker image `genomicpariscentre/tophat2`.\n",
    "\n",
    "```sos\n",
    "[tophat-align]\n",
    "# align reads using the TOPHAT aligner\n",
    "depends:  hg19_genes_gtf, hg19_fasta, \"${hg19_Bowtie2_index}/genome.1.bt2\"\n",
    "input:    fastq_files\n",
    "output:   \"${output_dir}/tophat_main/alignments.bam\"\n",
    "\n",
    "task:   queue='linux', to_host=hg19_Bowtie2_index,\n",
    "\t    from_host=\"${output_dir}/tophat_main\"\n",
    "\n",
    "R1 = sorted([x for x in input if '_R1_' in x])\n",
    "R2 = sorted([x for x in input if '_R2_' in x])\n",
    "stop_if(len(R1) != len(R2), \"Unequal number of R1 and R2 files from input ${fastq_files}\")\n",
    "\n",
    "# genomicpariscentre only has tophat2 (bowtie2) so it does not support option --bortie1\n",
    "run:    docker_image='genomicpariscentre/tophat2'\n",
    "\n",
    "\t[ -d ${output_dir} ] || mkdir -p ${output_dir}\n",
    "\ttophat2  \\\n",
    "\t\t--read-realign-edit-dist 1 \\\n",
    "\t\t--segment-length 24 \\\n",
    "\t\t-o '${output_dir}/tophat_main' \\\n",
    "\t\t-p 7 \\\n",
    "\t\t--GTF '${hg19_genes_gtf}' \\\n",
    "\t\t--rg-id 0 \\\n",
    "\t\t--rg-sample '${sample_name}' \\\n",
    "\t\t--library-type fr-firststrand \\\n",
    "\t\t--no-coverage-search \\\n",
    "\t\t--keep-fasta-order  \\\n",
    "\t\t--fusion-search --fusion-anchor-length 13 \\\n",
    "\t\t--fusion-ignore-chromosomes chrM,M '${hg19_Bowtie2_index}/genome' \\\n",
    "\t\t'${R1!ae,}' '${R2!ae,}'\n",
    "```\n",
    "\n",
    "When the step is executed, SoS will\n",
    "1. Transfer `hg19_genes_gtf`, `hg19_fasta`, `${hg19_Bowtie2_index}/genome.1.bt2` (specified by `depends`), `fastq_files` (specified by `input`) and `hg19_Bowtie2_index` (specified by `to_host`) to remote server.\n",
    "2. Translate all variables (`input`, `output`, etc).\n",
    "3. On server `linux`, before starting the script, download docker image `genomicpariscentre/tophat2` if not already available.\n",
    "4. Start the bash script in the docker container.\n",
    "\n",
    "With this setup, everything is provided and specified by the local host. The server does not have to have any data and software installed so you are free to make use of any server with docker installed."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos.jupyter.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "celltoolbar": true,
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "JavaScript",
     "javascript",
     "JavaScript",
     "#00ff80"
    ],
    [
     "Python2",
     "python2",
     "Python2",
     "#F6FAEA"
    ],
    [
     "rik_local_remote",
     "rik_local_remote",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#FDEDEC"
    ],
    [
     "Python3",
     "python3",
     "Python3",
     "#EAFAF1"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   }
  },
  "toc": {
   "nav_menu": {
    "height": "322px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
